"""
Deterministic ML Trading Strategy Backtester
with expanding-window walk-forward retraining (LSTM + simplified PPO)
FIXED: Timezone handling issues
"""

# =============================
# 0. Reproducibility Settings
# =============================
import os
import random
import numpy as np
import tensorflow as tf

os.environ['PYTHONHASHSEED'] = '42'
os.environ['TF_DETERMINISTIC_OPS'] = '1'
# Uncomment to force CPU-only execution (stronger determinism)
# os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)

# =============================
# 1. Imports
# =============================
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as yf
import warnings
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler, MinMaxScaler

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

tf.get_logger().setLevel('ERROR')

# =============================
# 2. Technical Indicators
# =============================
class TechnicalIndicators:
    @staticmethod
    def calculate_sma(data, window):
        return data.rolling(window=window).mean()

    @staticmethod
    def calculate_ema(data, window):
        return data.ewm(span=window).mean()

    @staticmethod
    def calculate_rsi(data, window=14):
        delta = data.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    @staticmethod
    def calculate_macd(data, fast=12, slow=26, signal=9):
        ema_fast = data.ewm(span=fast).mean()
        ema_slow = data.ewm(span=slow).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal).mean()
        histogram = macd_line - signal_line
        return macd_line, signal_line, histogram

    @staticmethod
    def calculate_bollinger_bands(data, window=20, num_std=2):
        sma = data.rolling(window=window).mean()
        std = data.rolling(window=window).std()
        upper_band = sma + (std * num_std)
        lower_band = sma - (std * num_std)
        return upper_band, sma, lower_band

    @staticmethod
    def calculate_volatility(data, window=20):
        return data.pct_change().rolling(window=window).std() * np.sqrt(252)

# =============================
# 3. Data Preprocessor
# =============================
class DataPreprocessor:
    def _init_(self):
        self.scaler = StandardScaler()
        self.price_scaler = MinMaxScaler()

    def fetch_data(self, symbol, start_date, end_date):
        try:
            ticker = yf.Ticker(f"{symbol}.NS")
            data = ticker.history(start=start_date, end=end_date)
            if data is None or data.empty:
                print(f"Warning: No data for {symbol} between {start_date} and {end_date}")
                return pd.DataFrame()
            
            # FIX: Convert timezone-aware index to timezone-naive
            if data.index.tz is not None:
                data.index = data.index.tz_convert(None)
            
            return data
        except Exception as e:
            print(f"Error fetching data for {symbol}: {e}")
            return pd.DataFrame()

    def add_features(self, df):
        df = df.copy()
        df['Returns'] = df['Close'].pct_change()
        df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))

        df['SMA_5'] = TechnicalIndicators.calculate_sma(df['Close'], 5)
        df['SMA_10'] = TechnicalIndicators.calculate_sma(df['Close'], 10)
        df['SMA_20'] = TechnicalIndicators.calculate_sma(df['Close'], 20)
        df['SMA_50'] = TechnicalIndicators.calculate_sma(df['Close'], 50)
        df['EMA_12'] = TechnicalIndicators.calculate_ema(df['Close'], 12)
        df['EMA_26'] = TechnicalIndicators.calculate_ema(df['Close'], 26)

        df['RSI'] = TechnicalIndicators.calculate_rsi(df['Close'])
        macd, signal, histogram = TechnicalIndicators.calculate_macd(df['Close'])
        df['MACD'] = macd
        df['MACD_Signal'] = signal
        df['MACD_Histogram'] = histogram

        upper_bb, middle_bb, lower_bb = TechnicalIndicators.calculate_bollinger_bands(df['Close'])
        df['BB_Upper'] = upper_bb
        df['BB_Middle'] = middle_bb
        df['BB_Lower'] = lower_bb
        df['BB_Width'] = (upper_bb - lower_bb) / (middle_bb.replace(0, np.nan))
        df['BB_Position'] = (df['Close'] - lower_bb) / ((upper_bb - lower_bb).replace(0, np.nan))

        df['Volume_SMA'] = TechnicalIndicators.calculate_sma(df['Volume'], 20)
        df['Volume_Ratio'] = df['Volume'] / (df['Volume_SMA'].replace(0, np.nan))

        df['Volatility'] = TechnicalIndicators.calculate_volatility(df['Close'])

        df['Price_SMA20_Ratio'] = df['Close'] / (df['SMA_20'].replace(0, np.nan))
        df['Price_SMA50_Ratio'] = df['Close'] / (df['SMA_50'].replace(0, np.nan))
        df['High_Low_Ratio'] = df['High'] / (df['Low'].replace(0, np.nan))

        df['Price_Change_5'] = df['Close'].pct_change(5)
        df['Price_Change_10'] = df['Close'].pct_change(10)

        return df

    def create_labels(self, df, threshold=0.02):
        df = df.copy()
        df['Future_Returns'] = df['Close'].shift(-1) / df['Close'] - 1
        df['Signal'] = 0
        df.loc[df['Future_Returns'] > threshold, 'Signal'] = 1
        df.loc[df['Future_Returns'] < -threshold, 'Signal'] = 2
        return df

# =============================
# 4. LSTM Model
# =============================
class LSTMModel:
    def _init_(self, sequence_length=60, units=50, dropout_rate=0.2):
        self.sequence_length = sequence_length
        self.units = units
        self.dropout_rate = dropout_rate
        self.model = None
        self.scaler = MinMaxScaler()
        self.is_trained = False

    def prepare_data(self, df):
        data = df['Close'].values.reshape(-1, 1)
        scaled_data = self.scaler.fit_transform(data)
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_data)):
            X.append(scaled_data[i-self.sequence_length:i, 0])
            y.append(scaled_data[i, 0])
        return np.array(X), np.array(y)

    def build_model(self, input_shape):
        self.model = Sequential([
            LSTM(self.units, return_sequences=True, input_shape=input_shape),
            Dropout(self.dropout_rate),
            LSTM(self.units, return_sequences=True),
            Dropout(self.dropout_rate),
            LSTM(self.units),
            Dropout(self.dropout_rate),
            Dense(25, activation='relu'),
            Dense(1)
        ])
        self.model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])

    def train(self, df, epochs=50, batch_size=32, validation_split=0.2):
        X, y = self.prepare_data(df)
        if len(X) < 100:
            print("Insufficient data for LSTM training")
            return None
        X = X.reshape((X.shape[0], X.shape[1], 1))
        if self.model is None:
            self.build_model((X.shape[1], 1))
        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        history = self.model.fit(
            X, y,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=validation_split,
            callbacks=[early_stopping],
            verbose=0,
            shuffle=False  # deterministic
        )
        self.is_trained = True
        return history

    def predict(self, df):
        if not self.is_trained:
            return None
        X, _ = self.prepare_data(df)
        X = X.reshape((X.shape[0], X.shape[1], 1))
        scaled_predictions = self.model.predict(X, verbose=0)
        predictions = self.scaler.inverse_transform(scaled_predictions)
        return predictions.flatten()

# =============================
# 5. PPO Agent (Deterministic during eval)
# =============================
class SimplePPOAgent:
    def _init_(self, state_size, action_size=3, learning_rate=0.0003):
        self.state_size = state_size
        self.action_size = action_size
        self.learning_rate = learning_rate
        self.policy_model = self._build_policy_model()
        self.value_model = self._build_value_model()
        self.is_trained = False

    def _build_policy_model(self):
        model = Sequential([
            Dense(64, activation='relu', input_shape=(self.state_size,)),
            Dense(32, activation='relu'),
            Dense(self.action_size, activation='softmax')
        ])
        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='categorical_crossentropy')
        return model

    def _build_value_model(self):
        model = Sequential([
            Dense(64, activation='relu', input_shape=(self.state_size,)),
            Dense(32, activation='relu'),
            Dense(1, activation='linear')
        ])
        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='mse')
        return model

    def get_action(self, state, deterministic=True):
        """If deterministic=True, choose argmax. If False, sample from policy."""
        if not self.is_trained:
            return 0
        state = np.reshape(state, [1, self.state_size])
        action_probs = self.policy_model.predict(state, verbose=0)[0]
        if deterministic:
            return int(np.argmax(action_probs))
        else:
            return int(np.random.choice(self.action_size, p=action_probs))

    def simple_train(self, states, actions, rewards, epochs=10):
        if len(states) < 50:
            return
        states = np.array(states)
        actions = np.array(actions)
        rewards = np.array(rewards)
        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)
        actions_onehot = tf.keras.utils.to_categorical(actions, self.action_size)
        for _ in range(epochs):
            self.policy_model.fit(states, actions_onehot, epochs=1, verbose=0, shuffle=False)  # deterministic
            self.value_model.fit(states, rewards, epochs=1, verbose=0, shuffle=False)          # deterministic
        self.is_trained = True

# =============================
# 6. Backtest Engine
# =============================
class BacktestEngine:
    def _init_(self, initial_capital=100000):
        self.initial_capital = initial_capital
        self.capital = initial_capital
        self.positions = {}
        self.trades = []
        self.portfolio_history = []
        self.transaction_cost = 0.001

    def reset(self):
        self.capital = self.initial_capital
        self.positions = {}
        self.trades = []
        self.portfolio_history = []

    def place_order(self, symbol, action, price, quantity, timestamp):
        if quantity <= 0:
            return False
        if action == 'BUY':
            cost = quantity * price * (1 + self.transaction_cost)
            if self.capital >= cost:
                self.capital -= cost
                self.positions[symbol] = self.positions.get(symbol, 0) + quantity
                trade = {'symbol': symbol, 'action': action, 'quantity': quantity, 'price': price, 'timestamp': timestamp, 'cost': cost}
                self.trades.append(trade)
                return True
        elif action == 'SELL':
            if self.positions.get(symbol, 0) >= quantity:
                revenue = quantity * price * (1 - self.transaction_cost)
                self.capital += revenue
                self.positions[symbol] -= quantity
                trade = {'symbol': symbol, 'action': action, 'quantity': quantity, 'price': price, 'timestamp': timestamp, 'revenue': revenue}
                self.trades.append(trade)
                return True
        return False

    def calculate_portfolio_value(self, current_prices):
        total_value = self.capital
        for symbol, quantity in self.positions.items():
            if quantity > 0:
                total_value += quantity * current_prices.get(symbol, 0)
        return total_value

    def record_portfolio_state(self, timestamp, current_prices):
        portfolio_value = self.calculate_portfolio_value(current_prices)
        state = {
            'timestamp': timestamp,
            'portfolio_value': portfolio_value,
            'capital': self.capital,
            'positions': self.positions.copy(),
            'return_pct': (portfolio_value - self.initial_capital) / self.initial_capital * 100
        }
        self.portfolio_history.append(state)

# =============================
# 7. Trading Strategy with Walk-Forward
# =============================
class TradingStrategy:
    def _init_(self, symbols, initial_capital=100000):
        self.symbols = symbols
        self.initial_capital = initial_capital
        self.data_processor = DataPreprocessor()
        self.lstm_models = {}
        self.ppo_agents = {}
        self.backtest_engine = BacktestEngine(initial_capital)
        self.train_data = {}
        self.test_data = {}
        self.feature_columns = [
            'SMA_5', 'SMA_10', 'SMA_20', 'RSI', 'MACD', 'MACD_Signal',
            'BB_Position', 'BB_Width', 'Volume_Ratio', 'Volatility',
            'Price_SMA20_Ratio', 'Price_Change_5', 'Price_Change_10'
        ]

    def load_data_range(self, symbol, start_date, end_date):
        raw = self.data_processor.fetch_data(symbol, start_date, end_date)
        if raw.empty:
            return raw
        f = self.data_processor.add_features(raw)
        f = self.data_processor.create_labels(f)
        return f.dropna()

    def load_all_data(self, full_start='2014-01-01', full_end='2024-12-31'):
        """Load full-range data once; we'll slice per windows later."""
        for sym in self.symbols:
            df = self.load_data_range(sym, full_start, full_end)
            if not df.empty:
                self.train_data[sym] = df  # holds full preprocessed df for slicing
            else:
                print(f"No data loaded for {sym}")

    def _train_models_for_symbol(self, symbol, train_df, val_df=None, lstm_epochs=30, ppo_epochs=10):
        """Train LSTM and PPO for a single symbol using provided train/val dfs (preprocessed, no NaNs)."""
        # LSTM
        lstm_model = LSTMModel(sequence_length=60)
        try:
            lstm_model.train(train_df, epochs=lstm_epochs, batch_size=32, validation_split=0.1 if val_df is None else 0.0)
        except Exception as e:
            print(f"LSTM training error for {symbol}: {e}")
        self.lstm_models[symbol] = lstm_model

        # PPO training dataset from train_df
        ppo_agent = SimplePPOAgent(state_size=len(self.feature_columns))
        states, actions, rewards = [], [], []
        for i in range(len(train_df) - 10):
            if i < len(self.feature_columns):
                continue
            state = train_df.iloc[i][self.feature_columns].values
            if not np.any(np.isnan(state)):
                states.append(state)
                actions.append(int(train_df.iloc[i]['Signal']))
                r = train_df.iloc[i]['Returns']
                rewards.append(r if not np.isnan(r) else 0.0)

        if len(states) > 100:
            ppo_agent.simple_train(states, actions, rewards, epochs=ppo_epochs)

        self.ppo_agents[symbol] = ppo_agent

    def generate_signal_for_symbol(self, symbol, current_data, deterministic=True):
        if symbol not in self.ppo_agents:
            return 0, {'reason': 'No PPO agent'}
        row = current_data.iloc[-1]
        try:
            state = row[self.feature_columns].values
            if np.any(np.isnan(state)):
                return 0, {'reason': 'NaN in state'}
            act = self.ppo_agents[symbol].get_action(state, deterministic=deterministic)
            return act, {'ppo_signal': act}
        except Exception as e:
            return 0, {'reason': str(e)}

    def walk_forward_backtest(
        self,
        train_start='2014-01-01',
        train_end='2022-12-31',
        val_start='2022-01-01',
        val_end='2023-01-01',
        test_start='2023-01-01',
        test_end='2024-12-31',
        retrain_step_days=90,
        lstm_epochs=30,
        ppo_epochs=10,
        position_size_pct=0.1,
        min_hold_days=1
    ):
        """
        Expanding-window walk-forward:
        - Train on [train_start : train_end]
        - Then iterate test windows from test_start..test_end in steps of retrain_step_days:
            - Evaluate on current test window
            - Expand training window to include that test window and retrain
        """

        # Ensure full data loaded
        for sym in self.symbols:
            if sym not in self.train_data:
                raise ValueError(f"Data for {sym} not loaded. Call load_all_data() first.")

        # FIX: Convert string dates to timezone-naive Timestamp objects
        train_slice_start = pd.to_datetime(train_start).tz_localize(None)
        train_slice_end = pd.to_datetime(train_end).tz_localize(None)

        # initial train
        for sym in self.symbols:
            df_full = self.train_data[sym]
            train_df = df_full[(df_full.index >= train_slice_start) & (df_full.index <= train_slice_end)].dropna()
            if len(train_df) < 200:
                print(f"Insufficient initial training data for {sym}; got {len(train_df)} rows.")
            self._train_models_for_symbol(sym, train_df, lstm_epochs=lstm_epochs, ppo_epochs=ppo_epochs)

        # backtester overall reset
        self.backtest_engine.reset()

        # FIX: Convert test dates to timezone-naive
        current_test_start = pd.to_datetime(test_start).tz_localize(None)
        final_test_end = pd.to_datetime(test_end).tz_localize(None)

        while current_test_start <= final_test_end:
            current_test_end = current_test_start + pd.Timedelta(days=retrain_step_days - 1)
            if current_test_end > final_test_end:
                current_test_end = final_test_end

            print(f"\n--- Evaluating window: {current_test_start.date()} -> {current_test_end.date()} ---")

            # collect dates that exist in ANY symbol's dataframe
            all_dates = set()
            for sym in self.symbols:
                df_full = self.train_data[sym]
                # FIX: Use proper timezone-naive comparison
                dmask = (df_full.index >= current_test_start) & (df_full.index <= current_test_end)
                all_dates.update(df_full.loc[dmask].index.date)
            all_dates = sorted(all_dates)

            # iterate dates and generate signals
            position_ages = {sym: 0 for sym in self.symbols}
            for date in all_dates:
                current_prices = {}
                # FIX: Convert date to timezone-naive datetime for comparison
                date_dt = pd.to_datetime(date).tz_localize(None)
                
                for sym in self.symbols:
                    df_full = self.train_data[sym]
                    date_mask = df_full.index <= date_dt
                    current_data = df_full.loc[date_mask]
                    if current_data.empty or len(current_data) < 70:
                        continue
                    current_price = current_data.iloc[-1]['Close']
                    current_prices[sym] = current_price

                    # generate deterministic signal for evaluation
                    signal, details = self.generate_signal_for_symbol(sym, current_data, deterministic=True)

                    # increment position age
                    position_ages[sym] = position_ages.get(sym, 0) + 1

                    current_position = self.backtest_engine.positions.get(sym, 0)
                    position_size = int(self.backtest_engine.capital * position_size_pct / (current_price + 1e-9))

                    if signal == 1 and current_position == 0:
                        if position_size > 0 and self.backtest_engine.place_order(sym, 'BUY', current_price, position_size, date):
                            position_ages[sym] = 0
                    elif signal == 2 and current_position > 0:
                        if position_ages.get(sym, 0) >= min_hold_days:
                            self.backtest_engine.place_order(sym, 'SELL', current_price, current_position, date)
                            position_ages[sym] = 0

                self.backtest_engine.record_portfolio_state(date, current_prices)

            print(f"Window completed. Portfolio value: {self.backtest_engine.portfolio_history[-1]['portfolio_value'] if self.backtest_engine.portfolio_history else 'N/A'}")

            # Expand training window for next iteration
            train_slice_end = min(train_slice_end + pd.Timedelta(days=retrain_step_days), final_test_end)
            for sym in self.symbols:
                df_full = self.train_data[sym]
                new_train_df = df_full[(df_full.index >= train_slice_start) & (df_full.index <= current_test_end)].dropna()
                if len(new_train_df) < 200:
                    print(f"Insufficient expanded training data for {sym}; got {len(new_train_df)} rows. Skipping retrain.")
                    continue
                print(f"Retraining models for {sym} on expanded window up to {current_test_end.date()} (rows: {len(new_train_df)})")
                self._train_models_for_symbol(sym, new_train_df, lstm_epochs=lstm_epochs, ppo_epochs=ppo_epochs)

            # step forward
            current_test_start = current_test_end + pd.Timedelta(days=1)

        print("\nWalk-forward backtest complete.")

    def analyze_results(self):
        if not self.backtest_engine.portfolio_history:
            print("No portfolio history to analyze.")
            return None
            
        perf_df = pd.DataFrame(self.backtest_engine.portfolio_history)
        perf_df['timestamp'] = pd.to_datetime(perf_df['timestamp'])
        perf_df.set_index('timestamp', inplace=True)
        
        final_value = perf_df['portfolio_value'].iloc[-1]
        total_return = (final_value - self.initial_capital) / self.initial_capital * 100
        
        daily_returns = perf_df['portfolio_value'].pct_change().dropna()
        volatility = daily_returns.std() * (252**0.5) * 100 if not daily_returns.empty else 0
        sharpe_ratio = (daily_returns.mean() * 252) / (daily_returns.std() * (252**0.5)) if daily_returns.std() > 0 else 0
        
        rolling_max = perf_df['portfolio_value'].expanding().max()
        drawdown = (perf_df['portfolio_value'] - rolling_max) / rolling_max * 100
        max_drawdown = drawdown.min() if not drawdown.empty else 0
        
        print("\n=== FINAL PERFORMANCE ===")
        print(f"Initial Capital: ₹{self.initial_capital:,.2f}")
        print(f"Final Portfolio Value: ₹{final_value:,.2f}")
        print(f"Total Return: {total_return:.2f}%")
        print(f"Annual Volatility: {volatility:.2f}%")
        print(f"Sharpe Ratio: {sharpe_ratio:.2f}")
        print(f"Max Drawdown: {max_drawdown:.2f}%")
        print("=========================")
        
        # Basic plot
        try:
            plt.figure(figsize=(12, 6))
            plt.plot(perf_df.index, perf_df['portfolio_value'], linewidth=2)
            plt.title('Portfolio Value Over Time (Walk-forward Backtesting)', fontsize=14)
            plt.ylabel('Portfolio Value (₹)', fontsize=12)
            plt.xlabel('Date', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.show()
        except Exception as e:
            print(f"Could not generate plot: {e}")
            
        return {
            'final_value': final_value,
            'total_return': total_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown
        }

# =============================
# 8. Example usage (main)
# =============================
def main():
    print("Starting ML Trading Strategy Backtester...")
    symbols = ['HDFCBANK']  # You can add more NSE symbols here
    strat = TradingStrategy(symbols, initial_capital=100000)
    
    print("Loading historical data...")
    strat.load_all_data(full_start='2014-01-01', full_end='2024-12-31')
    
    print("Running walk-forward backtest...")
    strat.walk_forward_backtest(
        train_start='2014-01-01',
        train_end='2022-12-31',
        val_start='2022-01-01', 
        val_end='2023-01-01',
        test_start='2023-01-01',
        test_end='2024-12-31',
        retrain_step_days=90,
        lstm_epochs=20,   # Reduced for faster execution
        ppo_epochs=8,
        position_size_pct=0.5,
        min_hold_days=1
    )

    # Analyze and display results
    results = strat.analyze_results()
    return results

if _name_ == '_main_':
    results = main()
